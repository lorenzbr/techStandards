6               methods for validating standards 6.1             different types of standard different types of standard require different forms of validation depending on the content of the standard and the methods used to define it. standards can be classified as follows: •     collections of definitions of terms such as taxonomies and ontology's.  •     methodological standards containing mainly text about methods and processes.  •     technical specifications typically containing a combination of text and partial models.  and •     test specifications defined by text and (partial) test suites for test systems. the present document differentiates between explicit and implicit validation methods. explicit validation methods encompass all those in which the primary objective is validation in itself, i.e. reviews, model-based validation, prototyping, and system testing [i.23]. implicit validation methods encompass those methods where the primary objective is not validating the standard but where validation is a by-product of the activity. implicit validation methods include requirements cataloguing, test development, product development and documentation. the selection of validation methods should be guided by the specification technique used within a standard. text is mainly informal and open for all review-based techniques. model-based validation is applicable to technical standards and test standards that contain (partial) models and/or test suites only. furthermore, all standards can be validated by the different implicit validation methods. 6.2             explicit validation 6.2.1           review methods 6.2.1.1             overview of reviewing methods systematic reviews are methods of reviewing specifications which, if used correctly, can identify many of the inaccuracies and inconsistencies present in the specifications. they are particularly effective when used to validate the following: •     text and other informally defined specifications.  •     sets of related standards where correlation and consistency between documents is essential. ieee 1028 [i.24] identifies a range of systematic review types which can be used in the validation of engineering design (specifically, software) specifications. these strictly controlled reviews work well in the large engineering project environment for which they are intended but could be considered as too strict for the standards engineering process. nevertheless, the fundamental approach to reviewing specifications can be an effective tool in the validation of standards. the types of review identified in ieee 1028 [i.24] include: •     management review -      a management study into a project's status and allocation of resources.  13                        etsi eg 201 015 v2.1.1 (2012-02) •     technical review -      a form of peer review in which a team of qualified personnel examines the suitability of the specification for its intended use and identifies discrepancies from its base requirements and other standards.  •     inspection -      a formal type of peer review where the reviewers follow a well-defined process to find defects [i.27].  •     walk-throughs -      a form of peer review where the author leads members of the editing team and other interested parties through a specification and the participants ask questions and make comments about defect.  and •     audits -      a type of review conducted by personnel external to the specification development project to evaluate compliance with requirements, standards, contractual agreements or other criteria. although each review method has its own particular use within an engineering design life-cycle, they all have fundamental similarities in the way they are constructed and managed: •     a group of impartial experts reviews a specification in detail in order to identify any defects that need to be rectified prior to publication -      these experts may have an interest in the document under review (as members of the responsible tc, for example) but should not have taken any direct role in its development.  •     one of the expert reviewers is appointed to chair and manage the review process.  •     any required changes are undertaken by the authors outside the review.  •     the process is iterative such that the revised document is resubmitted for further review until no further changes are required. 6.2.1.2              using reviews to validate standards review methods are unlikely to yield the same depth of validation that an automated, model-based technique can offer (see clause 6.2.2). however, reviews have the benefit that they can be used to validate any type of standard and do not depend on there being behavioural content within the specification. it is certain that the strict, systematic methods described in ieee 1028 [i.24] will identify a significant proportion of the defects in a design specification and this approach can be applied to the standardization process very effectively. despite this advantage, it is possible that the overheads in terms of effort and timescale will be unacceptable within the development schedules of some standards. in those cases, reviews can be used less formally although this is likely to be less effective in identifying defects. the process of approving standards using the etsi remote consensus procedure and the scrutiny of editorial consistency offered by the etsi edithelp service are both useful and valuable adjuncts to the more formal peer review process but they cannot be considered to be substitutes for it. 6.2.1.3              basic review process the process of organising and carrying out the review of a standard involves the same common set of steps regardless of the formality intended. this process, shown in figure 1, comprises 4 distinct phases, as follows: 1) planning. 2) preparation for the review. 3) document review meeting. 4) processing change proposals. 14                       etsi eg 201 015 v2.1.1 (2012-02) note:       the processing of change proposals (phase 4) takes place outside of the review process itself but it is included here as an essential part of the iteration loop. figure 1: document review process 6.2.1.3.1              phase 1: planning the review the planning phase of a review can start as soon as it is known when a draft of the document to be reviewed will be available. it is not necessary to wait until the draft, itself, has been completed. this phase of the process involves the following three steps: •    assign a leader for the review process. •    select and invite the reviewers. •    schedule a date for the review. 15                         etsi eg 201 015 v2.1.1 (2012-02) 6.2.1.3.1.1                assign a leader for the review process when selecting an individual to lead a review group it is not necessary to choose an expert in the subject under review, although this can be useful. it is much more important to find a leader who is: •     impartial -     no commercial, political or technical bias with respect to the document under consideration and, thus, unlikely to influence the outcome of the review unduly.  •     authoritative -     able to ensure that the review is successful by encouraging active participation by the reviewers, maintaining focus on the review subject and fostering consensus.  •     a good organizer in most cases, the review leader could be one of the following: •     the chair of the associated etsi technical body (tb) or working group (wg).  •     the etsi technical officer supporting the associated tb or wg.  or •     the document rapporteur if that person is not one of the contributing authors. this could be the case if, for example, the document is a deliverable from a specialist task force (stf). 6.2.1.3.1.2                select and invite the reviewers each reviewer of a document should be chosen on the basis of particular knowledge or expertise that they possess. it is unlikely that a single reviewer will have all the necessary skills but, between them, the reviewers should be conversant in all aspects of the technical content of the document under review and in the process for producing the document. the selected reviewers should, therefore, be: •     independent -     not one of the contributing authors.  •     knowledgeable -     capable in (at least part of) the subject area of the document or in the associated standards development process.  •     assigned specific responsibilities within the context of the review -     each should know why they have been selected as a reviewer and which clauses that they should pay particular attention to. there is no easy formula for determining how many reviewers should be selected but a smaller group is likely to be more effective than a large one. the size of the reviewers group will depend on a number of factors including: •     the quantity of material to be reviewed.  •     the breadth and depth of the technical content.  •     the availability of suitable reviewers. in many cases the membership of the responsible wg should be sufficient but, if this is a large group with a frequently changing membership then it may be necessary to appoint a sub-group for the reviewing task. 6.2.1.3.1.3                schedule a date for the review establishing a date and time for the review to take place should not be a time-consuming task but the following criteria are important: •     the date should be convenient for the leader, the reviewers and the author(s) of the document.  16                        etsi eg 201 015 v2.1.1 (2012-02) •     a sufficient period should be planned between the availability of the document and the review, itself -      this period will depend on the size of the document and the other commitments of the reviewers but it should be a minimum of two weeks but not so long that it affects progress in the development of the standard.  •     enough time is scheduled to complete the review -      this, too, will depend on the size of the document to be reviewed and also on its maturity but it is unlikely to take less than half a day and, for a large and immature document, could be two or more days. a previously unreviewed draft document is likely to require more time than one that is in its final stages before publication. frequent, incremental reviews throughout the development process are, therefore, a more efficient use of reviewers time and a more effective method of reviewing a draft standard. 6.2.1.3.2                phase 2: preparing for the review both the authors of a document and its reviewers have responsibilities immediately prior to the review. once the draft is available for the reviewers to study, they should: •     ensure that they understand the requirements and the overall objectives of the document and its related project.  •     read the document (or parts of the document) to be reviewed.  •     prepare constructive comments and questions to be put to the authors during the review. note:       there is no requirement for reviewers to record their comments in any specific format. the content of the comment is more important than its presentation form. however, the simple form shown in table a.1 in annex a can be used to capture the essential information associated with a reviewers comment. at the same time, the authors should prepare a short presentation summarizing: •     the purpose of the document under review.  •     the relationship of the document with other published or planned documents.  •     the status of the draft.  •     any new material added since its previous review.  •     any modifications since its previous review.  •     any special methods used during development.  •     objectives of the impending review. 6.2.1.3.3                phase 3: reviewing the specification a document review meeting will always be most effective if all the participants meet together in a common location. however, little effectiveness is lost if some or all of the participants join using remote meeting facilities. there are three distinct activities involved in the actual review of the draft document. these are: •     presentation of the overview from the document author(s).  •     inspection of the document.  •     preparation and agreement of any required change proposals. 6.2.1.3.3.1                 presentation of the overview from the document author(s) at the start of the review meeting one of the document authors should present the overview previously prepared during phase 2. purely as a guideline, this presentation will probably lack sufficient detail if it lasts less than 15 minutes and will contain too much information if it goes on beyond 30 minutes. at the end of the presentation the authors should be prepared to answer questions for clarification from the review leader and the group of reviewers. 17                         etsi eg 201 015 v2.1.1 (2012-02) 6.2.1.3.3.2                 inspection of the document the purpose of inspecting a document is to identify possible defects where either technical or editorial requirements have not been met. the most effective inspection method is to consider comments from the reviewers on a clause-by-clause basis but some flexibility should be allowed. in order to ensure efficient progress through the inspection, reviewers comments should be: •     fully justified -      enough information is provided to make it clear that the comment is valid.  •     impersonal -      comments should relate only to technical or editorial defects and should avoid personal comments regarding the authors.  •     supported by a proposed change -      comments should identify a possible defect in the reviewed document without offering an alternative solution for the authors to consider. 6.2.1.3.3.3                 preparation and agreement of any required change proposals each change proposal should be discussed and either accepted or rejected by the review group. if accepted, the change should be assigned to one (or more) of the document authors and scheduled for inclusion in the next or a future revision of the draft. it is particularly important that all accepted change proposals are recorded so that the resultant modifications to the document can be considered in a subsequent review. the reviewers change proposal form specified as table a.1 in annex a can be used for this purpose. alternatively, a revision of the reviewed draft document with change marks and comments would be a valid record of all accepted change proposals. if there are no change proposals accepted at the end of the review then the document can be considered to have completed its validation by peer-review. 6.2.1.3.4                phase 4: processing change proposals 6.2.1.3.4.1                 implement changes in a document revision if there are accepted change proposals at the end of the document review meeting, the authors should consider each of these and make the necessary modifications to the document. the task of implementing the accepted change proposals is outside the basic review process and should follow whatever method is normally used for revising draft documents within the associated tb. 6.2.1.3.4.2                 review actual changes before the revised document is resubmitted for review, the author(s) should discuss each of the implemented changes with the review leader to gain an independent opinion of whether the accepted change proposals have been implemented correctly. at this stage the review leader should expect the authors to justify any deviations from the accepted change proposals from the previous review. it may also be valuable at this stage to present the revisions to the wg or tb responsible for the document. 6.2.2           model-based validation methods it is possible to validate standards that specify behaviour (protocol and service standards, for example) more thoroughly by using model-based methods. these require at least part of the specified system to be defined in a formalized way using a fully-fledged general modelling technology (for example, sdl or uml) or a specific, partial modelling technique for selected aspects or views of the system (for example, asn.1 or msc). 18                      etsi eg 201 015 v2.1.1 (2012-02) model-based validation techniques such as simulation and state-space exploration offer the most rigorous and thorough validation of a protocol or service specification. however, both techniques require specific expertise and extensive resources to develop the requisite models and their application is further hindered by the non-existence of powerful tools able to cope with the modelling concepts required for (industrial) standards. any model-based validation method can be effective only if the following criteria can be met: •     parts of the standard are (or can be) modelled.  •     the proposed modelling techniques are standardized.  •     automated specification and analysis tools exist to support the proposed modelling techniques. if these criteria cannot be met then the review methods (see clause 6.2.1) and product-based methods (see clause 6.2.4) are likely to be the most effective means of validation. there are few modelling methods that are both standardized and supported by automated analysis tools. apart from the more established methods such as sdl, msc and uml, there are new methods available for the validation of a standard using significantly fewer resources. practical model-based validation methods include modelling and simulation using languages which include: •     specification and design language (sdl) [i.18].  •     unified modelling language (uml) [i.21].  •     message sequence charts (msc) [i.19].  •     life sequence charts (lsc) [i.31], [i.32]: -      a dialect of the msc language which is already commonly used as a specification method within protocol and service standards. 6.2.2.1             modelling and simulation scenario-based specification of system behaviour is often used in the development of technical standards where informal flow graphs and comparable techniques are used. the specification and design language (sdl) [i.18] is one of the few modelling techniques that is standardized and its use in validation is described in etr 184 [i.13]. however, although sdl design and simulation tools are available, there are no state-space exploration tools currently supported. in general, model simulation implies validation by inspection of the output of the simulation which is most often presented as mscs [i.19]. this is a useful method of validation but does not have the rigor of the methods described in etr 184 [i.13]. message sequence charts was one of the first formal specification techniques for visual scenario specification to be standardized in itu-t recommendation z.120 [i.19]. uml sequence diagrams are based on msc and have similar syntax and semantics. the life sequence chart methodology is a development of msc which supports the visual specification and simulation of reactive systems. they go beyond mscs by defining behavioural properties, i.e. 'things that must occur'. the additional lsc constructs are: •     scenarios: -      universal scenarios: describe system behaviour that applies in all instances.  specify action-reaction steps of the specified system.  -      existential scenario: monitored and observed during simulation.  •     pre-charts: -      define preconditions for the main charts. 19                     etsi eg 201 015 v2.1.1 (2012-02) lsc specifications help to define and analyse potential behavioural scenarios for implementing technical requirements within a standard. 6.2.2.2             model quality assessment a number of guidelines exist which define best practises for modelling system, component, service, protocol, process and other behaviour-oriented specifications. some are defined for a specific modelling notation while others are more general and relate to the entity to be modelled. useful examples of such guidelines are those published by scott w. ambler [i.25] and j. mendling et al [i.26]. these guidelines can be followed manually during reviews (see clause 6.2.1) or by static analysis tools which provide a thorough, complete and automated method of guideline checking. the quality of a model can also be validated by checking for the presences of modelling patterns that represent modelling practices to be followed and to check for the absence of modelling anti-patterns reflecting bad modelling styles. modelling patterns and anti-patterns can be rephrased as modelling guidelines.  however the reverse is typically not true. useful examples for modelling patterns and anti-patterns are defined by helmut neukirchen et al for test suites in ttcn-3 [i.28] and a flexible overall approach to model quality [i.29] is described by jens nodler et al. furthermore, model quality can be assessed with metrics that represent the complexity, readability, maintainability, coherence, and similar properties of modelling artefacts. metrics are typically derived automatically by tools as a manual calculation would be cumbersome and prone to errors [i.30]. such metrics are useful typically if large portions of a standard are specified or supported by models. 6.2.3           test suite validation a standardized conformance or interoperability test specification should be validated using similar methods to those for other standards. such a specification typically comprises [i.4], [i.17]: •     a set of test purposes such as those specified in the tplan notation [i.7].  •     the definition of a test suite structure and of the implementation conformance/interoperability statement and the extra information for testing (often defined textually).  •     an abstract test suite (ats) which is most often specified in ttcn-3 [i.6]. there are three levels of validation defined for ttcn-3 test specifications (see annex b), as follows: 1)    the test suite successfully analyses/compiles on one or more ttcn-3 test tools. optionally, a design review of the test suite is performed. 2)    the tests are executed on one test platform against at least one system under test (sut). where possible, tests will be run to completion. optionally, a back-to-back validation (mirror test cases) and/or a data-driven codec validation are performed. 3)    the tests are executed on several test platforms against several suts. tests will be run to completion and trace analysis will be done. further details on the validation processes for the three levels are given in annex b of the present document. 6.2.4           product-based validation (proof-by-use) 6.2.4.1             etsi plugtests™ events 6.2.4.1.1               benefits of using a testing events for validating standards an etsi's plugtests™ event is an organized event at which prototype or production implementations of a standard (or standards) are interconnected and tested for both interoperability and possibly conformance. such an event provides validation of both the base standard(s) and the implementations of the standard(s). 20                          etsi eg 201 015 v2.1.1 (2012-02) a plugtests™ event follows a pre-defined sequence of tests which is specified to provide either a comprehensive validation of the standard(s) or a more focussed one on a smaller part of the standard. this flexibility makes testing events very effective methods of validation even at an early stage of development. there are a number of benefits to be gained from a validation exercise based upon etsi plugtests™ events. these are: •      they provide validation of the standard(s) as well as a measure of interoperability capabilities and general behaviour of the implementations.  •      simultaneous validation of a set of standards (or multiple related standards) can be achieved more rapidly and with greater accuracy than with 'desk-top' methods such as peer reviews.  •      the sequences of tests can be arranged to target validation of specific functionality within the standard(s).  •      problems associated with implementation (for example, ambiguity of requirements, lack of clarity in the specification and over-complexity) are easier to locate because product must, necessarily, have implemented the standard(s) before the event can take place.  •      a single event can achieve in one week of cooperative testing what might otherwise take many months. 6.2.4.1.2                criteria for selecting a testing event for validation while testing events are very effective standards validation tools, they are not appropriate for all types of standards and the following criteria should be considered when determining whether to instigate validation based upon testing events: •      the standard(s) in question should specify some form of communications functionality -     plugtests™ events are usually based on the testing of intercommunication and interoperability and so they are particularly suited to the validation of protocol, service and transmission standards.  •      implementations of the standard are available for testing -     product development by two or more organizations should be proceeding either in parallel with the standards or even in advance.  -     product developers should be willing to take prototypes and development products to a testing event.  •      the complexity of the standardized specification should be sufficient that it would be difficult and time-consuming to validate it purely by inspection and review -     testing events are particularly well suited to the validation of sets of related standards or groups of related standards that do not necessarily depend upon each other (for example, groups of supplementary services or applications). if all of these criteria can be met then a testing event should be considered as a validation method. 6.2.4.1.3                overall process 6.2.4.1.3.1                 responsibilities once a decision has been made by a tb to use an etsi plugtests™ event as part of its validation process, there is a partnership that needs to be established between the various groups that will be involved in organizing, managing and participating in the event. each of the partners has specific responsibilities, as follows: •      etsi technical body: -     defining the scope of testing with respect to validation of the standard(s).  -     specifying the capabilities required from the systems under test (sut).  -     providing knowledge of the standard(s).  21                        etsi eg 201 015 v2.1.1 (2012-02) -     specifying the interoperability and, if appropriate, conformance tests to be undertaken during the event: automated test suites are capable of testing a greater proportion of the standardised requirements in a shorter time than equivalent manual testing. they are also able to produce more information on any failures that may occur.  •     industry: -     defining the scope of testing with respect to the evaluation of the products implementing the standard(s).  -     providing suts that offer the capabilities required for testing.  -     providing expertise in the standardized technology and the suts.  •     etsi centre for testing and interoperability (cti): -     providing expertise on testing methods and specifications.  -     providing technical and it support before and during the event: general management.  project coordination.  -     providing the testing and communications infrastructure.  -     providing expertise in the interconnection and operation of products within the communications infrastructure.  -     providing logistics support in organizing and managing the event.  -     maintaining an operational link to the tb. 6.2.4.1.3.2                factors to consider in making a plugtests™ event successful a plugtests™ event can only be a successful validation exercise if all the partners contribute to the preparation and execution of the event. there is no simple formula for determining how long it will take to prepare for a plugtests event as this period will vary considerably depending upon: •     the maturity of the technology being standardized.  •     the complexity of the standard specifications.  •     the availability of a range of suitable suts.  •     the availability of infrastructure resources.  •     the availability of logistical resources such as an organiser within etsi cti and a suitable venue. the chart in figure 2 shows the relationships between the activities involved and the responsibilities for each task. 22                        etsi eg 201 015 v2.1.1 (2012-02) figure 2: generic schedule for a plugtests™ event in some cases it will be possible to save time and money by having the suts communicating remotely over a public or other wide-area network provided by etsi cti. such an arrangement can make the synchronization and management of test activities more difficult but this can be outweighed by the fact that equipment does not need to be transported to a common location in order to carry out the testing. however, it is usually considered to essential to have representatives from each of the participating organizations present together in order to coordinate the testing and discuss the results. most testing events focus on the interoperability of the suts because it is easier to demonstrate the general behaviour of a product in respect of the standard(s) it has implemented by taking this approach. nevertheless, the effectiveness of the event for validation purposes will almost certainly be improved if some, or all, of the suts have successfully undergone some conformance testing before the event. information will be collected during the testing event and then compiled into a report for presentation to the 'client' tb afterwards. care is taken to ensure that this report is anonymous in that it does not identify the participating organizations nor any defects discovered in their products during the event. the primary purpose of the report is to identify and describe any defects found in the standard(s) during the event so that they can be rectified by the tb in a subsequent revision of the document(s). the time between the decision to use an interoperability event to validate the standard(s) and the completion of the feedback report (points a and b on the plan shown in figure 2) can vary considerably depending upon a number of factors. as examples, the time between points a and b can be as short as 3 months if: •     the underlying technology is mature.  •     the standards, themselves, are mature and have already been published in earlier versions.  •     products implementing the standard(s) already exist.  and •     interoperability events have already been used to validate previous versions of the standard(s). however, it may take as long as 2 years to realize an event if: •     the technology is novel and little experience of it is available.  •     the first edition of the standard(s) is under development within the tb and unpublished.  and •     industry is developing product implementations but do not have them available for testing. 23                          etsi eg 201 015 v2.1.1 (2012-02) 6.2.4.2               prototyping while the use of testing events is an extremely good way of validating protocol and service standards if product implementations are available, when the subject matter of a standard concerns physical characteristics rather than behaviour, it is a less effective method. in such cases, the only validation method which should be considered as an alternative to walk through is prototyping. this involves the implementation of a design specification in a small number of representative, rather than commercial, pieces of equipment for the purpose of demonstrating the feasibility of a concept or the correctness of the specification. the fabrication of prototype models usually requires highly skilled technicians working in a laboratory environment. as a result, the cost of prototypes can be high and, in some cases, prohibitive. these costs normally make it impossible for etsi to fund such implementations of its standards for validation purposes and it is, therefore, a method that can only be used if a member organization (or group of organizations) is willing to undertake the work. the use of a prototype model to validate a standard or set of standards, involves the following steps: •      a clear agreement is reached on which parts of the standard are to be modelled in the prototype.  •      a full schedule of tests and observations to be performed and the expected results is prepared and agreed before prototype validation begins.  •      prototype models are built using parts and methods that ensure that the models are completed as quickly and as accurately as possible within the constraints of the available resources.  •      testing is performed according to the agreed schedule.  •      a clear report is produced giving details of: -       problems found in the specification during manufacture and system testing.  -       the actual results of validation testing.  -       the impact of the results on the standard.  •      the results are reviewed by the responsible tb and actions assigned to ensure that any necessary changes to the standard are completed. this is likely to be an iterative process where the modifications to the standard as a result of the validation exercise are incorporated into the prototype model(s) and re-tested. when planning to use prototyping as a means of validating a standard, the following aspects should be taken into consideration: •      prototypes can be used to model partial specifications as well as complete specifications.  •      existing commercial products can be used as platforms for testing prototype functions.  •      it is essential that the organization(s) carrying out the building and testing of prototype models share the results of the project with the other members of the responsible etsi technical committee. 6.3               implicit validation 6.3.1             requirements cataloguing the specification of a broad technology often takes place across multiple standardization bodies and so the set of requirements to be implemented comes from a range of documents produced in disparate styles. building a coherent set of test specifications from such disperse sources can be simplified by gathering the requirements together into a single requirements catalogue [i.5]. this lists all implementation requirements from the various sources and organizes them into an appropriate structure. it is often created as a tree structure based upon standardized functionality with each node of the tree representing a specified function. 24                         etsi eg 201 015 v2.1.1 (2012-02) although the primary purpose of a catalogue is to collect together the base requirements prior to the development of conformance and interoperability test specifications, the process of collating it can have considerable benefits in validating the catalogued standards. the development of a catalogue involves close analysis of the text in the base standards in order to find: •      explicit implementation requirements.  •      implicit implementation requirements.  •      duplicated requirements.  •      contradictory requirements.  and •      incomplete or otherwise incorrect requirements. the nature of the cataloguing process in recording all requirements means that very little additional effort is required to benefit from the coincidental validation. all that is required is to report back to the originating committee on the implicit, duplicate, contradictory and incorrect requirements so that they can be improved in a later release of the standard(s). examples of published requirements catalogues can be found in ts 102 558 [i.9] (ipv6 security) and in ts 102 795 [i.11] (digital private mobile radio). 6.3.2            test specification development the development of test specifications can only commence when there is a collection of testable requirements (see also clause 6.3.1) available. a test specification developed under the methodologies in use at etsi for conformance testing [i.17] and interoperability testing [i.4] should include the following documentation: •      an implementation conformance statement (ics) or an interoperable functions statement (ifs).  •      a test suite structure (tss).  •      a set of test purposes.  •      an abstract test suite (ats) comprising either (or both): -     test descriptions (td).  -     test cases (tc).  •      an implementation extra information for testing (ixit) statement. the process of producing either interoperability of conformance tests specifications requires close inspection of the standard(s) to be tested. each of the requirements needs to be located and analysed individually and in combination before tests can be written for them. this will result in a level of validation similar to that offered by a rigorous peer review (see clause 6.2.1). 6.3.2.1              ics and ifs the ics and the ifs are similar questionnaires on the optional and mandatory features specified for an implementation of a given standard. they are used to determine whether all mandatory features are implemented and which optional ones. the development of the ics or ifs helps to check that all mandatory and optional features are clearly stated and well described. the questions in the implementation statement should be linked to the requirements in the base standard and, if it exists, the requirements catalogue. guidelines on the specification of an ics and an ifs are described in etr 212 [i.14] and eg 202 237 [i.4] respectively. 6.3.2.3             test purposes the tps describe the purpose of each potential test case in determining whether the requirements in the base standard or the requirements catalogue have been met. the development of tps involves the identification and understanding of each of the requirements in the base standard even if there is no requirements catalogue available to simplify the task. this process indirectly reviews the completeness, accuracy and comprehensibility of the base requirements. examples of published tps can be found in ts 102 385-2 (wimax/hiperman) [i.8], ts 102 593 (ipv6 security) [i.10] and ts 102 870-2 (its basic transport protocol) [i.12]. 6.3.2.4             test suite the test suite itself defines the functional details of the test which are outlined in the test suite structure and test purposes. it is the basis for automated conformance and interoperability testing (see clause 6.3.3), but can also serve for manual testing where needed. the development of test cases necessarily involves detailed analysis of the individual requirements in the base standards and the requirements catalogue. in this way it is possible to determine whether the requirements have been expressed precisely enough in stating how an implementation should behave. automated test cases are usually specified in the ttcn-3 language [i.6] and this formalized approach can locate other inconsistencies, ambiguities and open issues in the base standard. 6.3.2.5             ixit the ixit poses questions related to the implementation which are necessary for test execution. it is a means of determining that all configuration and parameterization options of an implementation are well-defined and correctly captured in the test specification as well as in the standard. 6.3.3           conformance and interoperability testing conformance testing is the process of establishing the extent to which a system under test (sut) satisfies conformance requirements as defined in the implementation conformance statement (ics). it ensures that a product correctly implements the standard and is able to exchange directives and information with another implementation using a known protocol or set of protocols. testing the conformance of a product to a standard is considered to be essential in ensuring that the product is able to inter-operate with other products that implement the same standard or a complementary one. ets 300 406 [i.15] describes a methodology which should be followed when producing conformance test specifications. a conformance test consists of two parts [i.17]: •     the static conformance review checking whether the choices between the implementation options that the manufacturer claims to have implemented is a combination permitted by the standard.  •     the dynamic conformance test using test case execution to determine whether the product has implemented the standard correctly. interoperability is the linking of systems, networks or services so that they can work together successfully. interoperability testing is achieved by connecting devices from different vendors and operating them, either manually or automatically, according to scenarios based on a protocol standard. interoperability testing is often performed at multi- vendor events in order to obtain valuable information about the capability of inter-operation of similar products. this is an approach often employed in an etsi plugtests™ event at various stages during the development cycle (see clause 6.2.4.1). conformance testing and interoperability testing are complimentary to each other. each has its strengths and weaknesses but together they can provide the best assurance that products will interoperate. 26                          etsi eg 201 015 v2.1.1 (2012-02) each test case in a conformance or interoperability test suite is related to one or more requirement of the base standard. the execution of a standardized test suite against an implementation of the base standard can help to validate the test suite itself as well as providing a final validation of the standard by exercising and observing the functionality of an implementation. in this way it is possible to identify requirements that have been specified accurately and unambiguously but which define unwanted or unexpected behaviour. 6.3.4            development of descriptive and guidance documentation although it is not usual for guides or tutorials to be published for simple standards, it can be useful to develop such documentation for standards that specify more complex technologies, particularly when the specification spans a number of different standards. such guides include: •     technology overviews.  •     implementation handbooks.  •     design guides.  •     future standardization proposals.  and •     testing frameworks. the development of descriptive and guidance documentation requires a good understanding of the standardized technology and, as with a requirements catalogue (see clause 6.3.1), a close inspection of the base text. again, little additional effort is required for the validation to be quite thorough but is important. 6.3.5            product development in much the same way as prototype development can be used a means of validating a standard (see clause 6.2.4.2), the development of marketable products which implement the standard can also provide a measure of validation. however, this approach may not be as effective for the following reasons: •     validation of the standard is coincidental rather than the main objective of the exercise. consequently: -      there may not be a predefined schedule of validation tests to be carried out during development.  -      there is less likelihood that necessary changes to the standard will be identified and reported back to the responsible tb.  •     correcting and reworking the standard at this stage is likely to be more costly than if validation had been undertaken explicitly earlier in the process. 6.4              validation best practice 6.4.1            identify the most appropriate validation level 6.4.1.1              defined validation levels it is not practical to consider using all of the validation methods specified in the present document but it is useful to consider validation at different levels. in this way it may be easier to determine which combination of validation methods is most appropriate for each standard or set of standards. validation of standards can be defined in three levels where level 1 represents the basic validation expected for a standard and level 3 the most rigorous. these levels are defined as follows: •     level 1 validation (basic): -      informal review of the standard(s) has taken place within the responsible committee or working group.  27                         etsi eg 201 015 v2.1.1 (2012-02) -    all formal language segments have been syntax checked by software tools: asn.1.  sdl.  uml: ·     class diagrams.  ·     sequence diagrams.  ·     state diagrams.  -    the standard has been approved by the tc/wg using the etsi remote consensus procedure.  -    the editorial consistency of the standard has been scrutinized by etsi edithelp service.  and -    for standards that specify protocols or services only, a plugtests™ event has been held during the development of the standard. only informally specified tests were executed. •  level 2 validation (strong): -    level 1 validation.  -    formal peer reviews have been undertaken throughout development of the standard.  and -    at least one of the following implicit validation method(s) have been undertaken: a test specification has been developed.  a requirements catalogue has been compiled.  a design guide or other supporting documentation has been produced.  one or more implementations of the standard have been incorporated into commercial products.  or -    the behaviour specified in a protocol or service standard has been examined using one or more of the following methods: behaviour models have been specified (using sdl, uml or other modelling language), compiled and simulated and the resultant message sequences inspected.  one or more prototype implementation has been developed specifically for the purpose of evaluating the standard.  an additional plugtests™ event based on more structured test specifications has been organized towards the end of development. •  level 3 validation (rigorous): -    level 2 validation.  and -    the behaviour specified in a protocol or service standard has been evaluated using one or more of the following methods: model-based validation tools have been used to assess the behaviour, integrity and completeness of the specification.  implementations of the standard have been evaluated in a programme of etsi plugtests events using an evolving set of structured tests throughout the development period. note:  the validation levels described here are intended primarily for use with respect to base (i.e. non-test) specifications. an established definition of validation levels related to test specifications can be found in annex b. 28                         etsi eg 201 015 v2.1.1 (2012-02) 6.4.1.2            select the required method(s) the most effective and appropriate method of validating a standard will depend upon a number of different factors which include: •     the content of the standard, for example: -     protocol and service standards can be validated using all of the methods specified in the present document.  -     standards specifying physical characteristics can be validated most easily by peer review or prototyping.  •     the complexity of the specification, for example: -     a standard specifying a simple protocol may not justify the expense of a plugtests™ event.  -     a complex technology specified across a number of standards may be difficult to validate fully in a peer review (even though the individual parts would benefit from separate reviews).  •     the availability of personnel with the necessary skills and experience.  •     the availability of the required resources.  •     the personal preferences of the rapporteur and technical committee responsible for the standard(s). these and other factors should be taken into consideration when making the choice of validation method. there is not, however, a right and wrong answer regarding this choice and it may be effective to select more than one method (a combination of explicit and implicit validation methods for example). it is important to choose methods that are effective and which the responsible technical committee is willing to use. 6.4.1.3            plan validation into the standards development process when considering the development of a standard or a set of standards it is useful to know not only what the specific technical requirements are which need to be met by the contents of the documents but also what validation activity is to be applied to the finished drafts. it follows that the validation of a standard should be planned together with its development. the definition of a comprehensive validation plan should give consideration to the following aspects: •     what type of validation will be used? -     peer review.  -     model-based.  -     plugtests™ event.  -     implicit validation (through test development etc.).  -     other.  -     a combination of methods.  or -     none.  note 1: the type of validation depends on the expected results of the standard development process. if the resultant deliverable will specify function or behaviour, the object of validation may be an executable validation model. in that case formal validation supported by automated software tools should be considered in the plan. •     what are the prerequisites for validation? -     standards.  -     guidance material.  -     reporting pro-formas.  29                      etsi eg 201 015 v2.1.1 (2012-02) -      procedures.  -      resources: implementations.  testing facilities.  personnel for testing or reviewing.  office or lab space.  •     when should validation activities take place? -      in relation to the development of the standard.  -      in relation to the availability of related standards.  -      in relation to the availability of products implementing the standard(s).  -      at various points within the development or once only.  •     what equipment is necessary for successful validation? -      software for model development and simulation.  -      processing platforms for validation tools.  -      special test equipment.  •     what will be the output of the validation activity? -      validation results.  -      change requests. it will not be necessary to plan all of the above items into the development schedule and tasks and resources necessary will depend upon the validation methods selected. the list is intended to act as an 'aide memoire' at the start of the standards development process to ensure that the most effective and efficient approach to validation is chosen and integrated into the overall activity. eg 202 107 [i.3] contains some useful algorithms for estimating the amount of effort required for many of the validation methods described in the present document. note 2: eg 202 107 [i.3] refers only to the use of the specification and design language, sdl [i.18], for model-based validation but its guidelines on estimating effort should apply equally well to other approaches. 6.4.1.4             resolve problems detected during validation one of the activities that is common to all of the validation methods described in the present document is the reporting of problems found in the validated standard back to the responsible technical committee. there is no single problem reporting system for etsi documents and each technical committee manages change requests (cr) in different ways. any problems or improvements identified during the validation process should be reported using whatever problem management system is in common use within the committee responsible for the standard. it is then the responsibility of that committee to review each cr, accept or reject it, respond to the originator and, if required, devise a change to the standard. 30                        etsi eg 201 015 v2.1.1 (2012-02)
